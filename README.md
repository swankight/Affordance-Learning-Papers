# Affordance-Learning-Papers

### Affordance Learning
- ###### [2025 ICLR] [3D-AffordanceLLM: Harnessing Large Language Models for Open-Vocabulary Affordance Detection in 3D Worlds.](https://openreview.net/pdf?id=GThTiuXgDC)
- ###### [2025 CVPR] [Grounding 3D Object Affordance with Language Instructions, Visual Observations and Interactions.](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Grounding_3D_Object_Affordance_with_Language_Instructions_Visual_Observations_and_CVPR_2025_paper.pdf)
- ###### [2025 CVPR] [SeqAfford: Sequential 3D Affordance Reasoning via Multimodal Large Language Model.](https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_SeqAfford_Sequential_3D_Affordance_Reasoning_via_Multimodal_Large_Language_Model_CVPR_2025_paper.pdf)
- ###### [2024 CoRL] [UAD: Unsupervised Affordance Distillation for Generalization in Robotic Manipulation.](https://openreview.net/pdf?id=an953WOpo2) 
- ###### [2024 CVPR] [One-Shot Open Affordance Learning with Foundation Models.](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_One-Shot_Open_Affordance_Learning_with_Foundation_Models_CVPR_2024_paper.pdf)
- ###### [2024 CVPR] [SceneFun3D: Fine-Grained Functionality and Affordance Understanding in 3D Scenes.](https://openaccess.thecvf.com/content/CVPR2024/papers/Delitzas_SceneFun3D_Fine-Grained_Functionality_and_Affordance_Understanding_in_3D_Scenes_CVPR_2024_paper.pdf)
- ###### [2024 CVPR] [LASO: Language-guided Affordance Segmentation on 3D Object.](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_LASO_Language-guided_Affordance_Segmentation_on_3D_Object_CVPR_2024_paper.pdf)
- ###### [2024 CVPR] [AffordanceLLM: Grounding Affordance from Vision Language Models.](https://openaccess.thecvf.com/content/CVPR2024W/OpenSUN3D/papers/Qian_AffordanceLLM_Grounding_Affordance_from_Vision_Language_Models_CVPRW_2024_paper.pdf)
- ###### [2023 ICCV] [ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding.](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_ViewRefer_Grasp_the_Multi-view_Knowledge_for_3D_Visual_Grounding_ICCV_2023_paper.pdf)
- ###### [2023 ICCV] [Understanding 3D Object Interaction from a Single Image.](https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Understanding_3D_Object_Interaction_from_a_Single_Image_ICCV_2023_paper.pdf)
- ###### [2023 ICCV] [Multi-label affordance mapping from egocentric vision.](https://openaccess.thecvf.com/content/ICCV2023/papers/Mur-Labadia_Multi-label_Affordance_Mapping_from_Egocentric_Vision_ICCV_2023_paper.pdf)
- ###### [2023 ICCV] [Grounding 3D Object Affordance from 2D Interactions in Images.](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Grounding_3D_Object_Affordance_from_2D_Interactions_in_Images_ICCV_2023_paper.pdf)
- ###### [2023 CVPR] [Affordances from Human Videos as a Versatile Representation for Robotics.](https://openaccess.thecvf.com/content/CVPR2023/papers/Bahl_Affordances_From_Human_Videos_as_a_Versatile_Representation_for_Robotics_CVPR_2023_paper.pdf)
- ###### [2023 CVPR] [Locate: Localize and transfer object parts for weakly supervised affordance grounding.](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_LOCATE_Localize_and_Transfer_Object_Parts_for_Weakly_Supervised_Affordance_CVPR_2023_paper.pdf)
- ###### [2023 CVPR] [Affordance Grounding from Demonstration Video to Target Image.](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Affordance_Grounding_From_Demonstration_Video_To_Target_Image_CVPR_2023_paper.pdf)
- ###### [2023 CVPR] [Leverage Interactive Affinity for Affordance Learning.](https://openaccess.thecvf.com/content/CVPR2023/papers/Luo_Leverage_Interactive_Affinity_for_Affordance_Learning_CVPR_2023_paper.pdf)
- ###### [2022 CVPR] [Learning affordance grounding from exocentric images.](https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_Learning_Affordance_Grounding_From_Exocentric_Images_CVPR_2022_paper.pdf)
- ###### [2021 IJCAI] [One-shot affordance detection.](https://www.ijcai.org/proceedings/2021/0124.pdf)

### Affordance + Foundation model 
- ###### [2025 ICLR] [3D-AffordanceLLM: Harnessing Large Language Models for Open-Vocabulary Affordance Detection in 3D Worlds.](https://openreview.net/pdf?id=GThTiuXgDC)
- ###### [2025 CVPR] [Grounding 3D Object Affordance with Language Instructions, Visual Observations and Interactions.](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Grounding_3D_Object_Affordance_with_Language_Instructions_Visual_Observations_and_CVPR_2025_paper.pdf)
- ###### [2025 CVPR] [SeqAfford: Sequential 3D Affordance Reasoning via Multimodal Large Language Model.](https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_SeqAfford_Sequential_3D_Affordance_Reasoning_via_Multimodal_Large_Language_Model_CVPR_2025_paper.pdf)
- ###### [2024 CoRL] [UAD: Unsupervised Affordance Distillation for Generalization in Robotic Manipulation.](https://openreview.net/pdf?id=an953WOpo2) 
- ###### [2024 CVPR] [One-Shot Open Affordance Learning with Foundation Models.](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_One-Shot_Open_Affordance_Learning_with_Foundation_Models_CVPR_2024_paper.pdf)
- ###### [2023 ICCV] [ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding.](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_ViewRefer_Grasp_the_Multi-view_Knowledge_for_3D_Visual_Grounding_ICCV_2023_paper.pdf)

### Affordance + Articulated object 
- ###### [2023 NIPS] [Where2Explore: Few-shot Affordance Learning for Unseen Novel Categories of Articulated Objects.](https://papers.neurips.cc/paper_files/paper/2023/file/0e7e2af2e5ba822c9ad35a37b31b5dd4-Paper-Conference.pdf)
- ###### [2023 NIPS] [Learning Environment-Aware Affordance for 3D Articulated Object Manipulation under Occlusions.](https://proceedings.neurips.cc/paper_files/paper/2023/file/bf78fc727cf882df66e6dbc826161e86-Paper-Conference.pdf)
- ###### [2023 NIPS] [MultiScan: Scalable RGBD scanning for 3D environments with articulated objects.](https://proceedings.neurips.cc/paper_files/paper/2022/file/3b3a83a5d86e1d424daefed43d998079-Paper-Conference.pdf)
- ###### [2023 ICCV] [MAAL:Multimodality-Aware Autoencoder-based Affordance Learning for 3D Articulated Objects.](https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_MAAL_Multimodality-Aware_Autoencoder-Based_Affordance_Learning_for_3D_Articulated_Objects_ICCV_2023_paper.pdf)
- ###### [2023 CVPR] [Affordances from Human Videos as a Versatile Representation for Robotics.](https://openaccess.thecvf.com/content/CVPR2023/papers/Bahl_Affordances_From_Human_Videos_as_a_Versatile_Representation_for_Robotics_CVPR_2023_paper.pdf)

### Action/Motion generation
- ###### [2024 CVPR] [Move as You Say, Interact as You Can: Language-guided Human Motion Generation with Scene Affordance.](https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_Move_as_You_Say_Interact_as_You_Can_Language-guided_Human_CVPR_2024_paper.pdf)
- ###### [2023 ICLR] [Human motion diffusion model.](https://openreview.net/pdf?id=SJ1kSyO2jwu)
- ###### [2023 ICCV] [PhysDiff: Physics-Guided Human Motion Diffusion Model.](https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_PhysDiff_Physics-Guided_Human_Motion_Diffusion_Model_ICCV_2023_paper.pdf)
- ###### [2023 ICCV] [Learning Foresightful Dense Visual Affordance for Deformable Object Manipulation.](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Learning_Foresightful_Dense_Visual_Affordance_for_Deformable_Object_Manipulation_ICCV_2023_paper.pdf)

### Part segmentation
- ###### [2025 ECCV] [Semantic-SAM: Segment and Recognize Anything at Any Granularity.](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/06495.pdf)
- ###### [2024 arvix] [Search3D: HierarchicalOpen-Vocabulary 3D Segmentation.](https://arxiv.org/pdf/2409.18431v1)
- ###### [2024 NIPS] [Hierarchical Open-vocabulary Universal Image Segmentation.](https://proceedings.neurips.cc/paper_files/paper/2023/file/43663f64775ae439ec52b64305d219d3-Paper-Conference.pdf)
- ###### [2023 NIPS] [OV-PARTS: Towards Open-Vocabulary Part Segmentation.](https://proceedings.nips.cc/paper_files/paper/2023/file/dde53059fdb0f45e1e9ad9c66997d662-Paper-Datasets_and_Benchmarks.pdf)
- ###### [2023 ICCV] [Going Denser with Open-Vocabulary Part Segmentation.](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Going_Denser_with_Open-Vocabulary_Part_Segmentation_ICCV_2023_paper.pdf)

### 3D scene understanding (segmentation)
- ###### [2024 CVPR] [SAI3D: Segment Any Instance in 3D Scenes.](https://openaccess.thecvf.com/content/CVPR2024/papers/Yin_SAI3D_Segment_Any_Instance_in_3D_Scenes_CVPR_2024_paper.pdf)
- ###### [2024 ECCV] [Segment3D: Learning Fine-Grained Class-Agnostic 3D Segmentation without Manual Labels.](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05027.pdf)
- ###### [2023 NIPS] [OpenMask3D: Open-Vocabulary 3D Instance Segmentation.](https://proceedings.neurips.cc/paper_files/paper/2023/file/d77b5482e38339a8068791d939126be2-Paper-Conference.pdf)
- ###### [2023 CVPR] [OpenScene: 3D Scene Understanding with Open Vocabularies.](https://openaccess.thecvf.com/content/CVPR2023/papers/Peng_OpenScene_3D_Scene_Understanding_With_Open_Vocabularies_CVPR_2023_paper.pdf)
- ###### [2023 ICCV] [ScanNet++: A High Fidelity Dataset of 3D Indoor Scenes.](https://openaccess.thecvf.com/content/ICCV2023/papers/Yeshwanth_ScanNet_A_High-Fidelity_Dataset_of_3D_Indoor_Scenes_ICCV_2023_paper.pdf)
- ###### [2022 NIPS] [MultiScan: Scalable RGBD scanning for 3D environments with articulated.](https://proceedings.neurips.cc/paper_files/paper/2022/file/3b3a83a5d86e1d424daefed43d998079-Paper-Conference.pdf) 
- ###### [2022 ECCV] [Language-Grounded Indoor 3D Semantic Segmentation in the Wild.](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136930121.pdf)

### Open-vocabulary segmentation
- ###### [2024 CVPR] [Open-Vocabulary Segmentation with Semantic-Assisted Calibration.](https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_Open-Vocabulary_Segmentation_with_Semantic-Assisted_Calibration_CVPR_2024_paper.pdf)
- ###### [2024 TPAMI] [A Survey on Open-Vocabulary Detection and Segmentation: Past, Present, and Future.](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10558790)
- ###### [2023 ICCV] [Zero-guidance Segmentation Using Zero Segment Labels.](https://openaccess.thecvf.com/content/ICCV2023/papers/Rewatbowornwong_Zero-guidance_Segmentation_Using_Zero_Segment_Labels_ICCV_2023_paper.pdf) 
- ###### [2023 ICCV] [A Simple Framework for Open-Vocabulary Segmentation and Detection.](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_A_Simple_Framework_for_Open-Vocabulary_Segmentation_and_Detection_ICCV_2023_paper.pdf)
- ###### [2023 CVPR] [Open-Vocabulary Semantic Segmentation with Mask-adapted CLIP.](https://openaccess.thecvf.com/content/CVPR2023/papers/Liang_Open-Vocabulary_Semantic_Segmentation_With_Mask-Adapted_CLIP_CVPR_2023_paper.pdf)
- ###### [2023 CVPR] [FreeSeg: Unified, Universal and Open-Vocabulary Image Segmentation.](https://openaccess.thecvf.com/content/CVPR2023/papers/Qin_FreeSeg_Unified_Universal_and_Open-Vocabulary_Image_Segmentation_CVPR_2023_paper.pdf)
- ###### [2023 NIPS] [Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen Convolutional CLIP.](https://papers.neurips.cc/paper_files/paper/2023/file/661caac7729aa7d8c6b8ac0d39ccbc6a-Paper-Conference.pdf)

### Zero-shot semantic segmentation
- ###### [2024 AAAI] [Spectral Prompt Tuning: Unveiling Unseen Classes for Zero-Shot Semantic Segmentation.](https://ojs.aaai.org/index.php/AAAI/article/view/28456)
- ###### [2024 CVPR] [Exploring Regional Clues in CLIP for Zero-Shot Semantic Segmentation.](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Exploring_Regional_Clues_in_CLIP_for_Zero-Shot_Semantic_Segmentation_CVPR_2024_paper.pdf)
- ###### [2023 CVPR] [ZegCLIP: Towards Adapting CLIP for Zero-shot Semantic Segmentation.](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_ZegCLIP_Towards_Adapting_CLIP_for_Zero-Shot_Semantic_Segmentation_CVPR_2023_paper.pdf)
- ###### [2023 CVPR] [Delving into Shape-aware Zero-shot Semantic Segmentation.](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Delving_Into_Shape-Aware_Zero-Shot_Semantic_Segmentation_CVPR_2023_paper.pdf)
- ###### [2023 CVPR] [Primitive Generation and Semantic-related Alignment for Universal Zero-Shot Segmentation.](https://openaccess.thecvf.com/content/CVPR2023/papers/He_Primitive_Generation_and_Semantic-Related_Alignment_for_Universal_Zero-Shot_Segmentation_CVPR_2023_paper.pdf)
- ###### [2019 NIPS] [Zero-Shot Semantic Segmentation.](https://proceedings.neurips.cc/paper_files/paper/2019/file/0266e33d3f546cb5436a10798e657d97-Paper.pdf)

### Few-shot semantic segmentation
- ###### [2024 CVPR] [APSeg: Auto-Prompt Network for Cross-Domain Few-Shot Semantic Segmentation.](https://openaccess.thecvf.com/content/CVPR2024/papers/He_APSeg_Auto-Prompt_Network_for_Cross-Domain_Few-Shot_Semantic_Segmentation_CVPR_2024_paper.pdf) 
- ###### [2024 CVPR] [Dynamic Knowledge Adapter with Probabilistic Calibration for Generalized Few-Shot Semantic Segmentation.](https://openaccess.thecvf.com/content/CVPR2024W/L3D-IVU/papers/Tong_Dynamic_Knowledge_Adapter_with_Probabilistic_Calibration_for_Generalized_Few-Shot_Semantic_CVPRW_2024_paper.pdf)
- ###### [2024 AAAI] [Label-Efficient Few-Shot Semantic Segmentation with Unsupervised Meta-Training.](https://ojs.aaai.org/index.php/AAAI/article/view/28094/28193)
- ###### [2023 CVPR] [Learning Orthogonal Prototypes for Generalized Few-shot Semantic Segmentation.](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Learning_Orthogonal_Prototypes_for_Generalized_Few-Shot_Semantic_Segmentation_CVPR_2023_paper.pdf)
- ###### [2023 CVPR] [MIANet: Aggregating Unbiased Instance and General Information for Few-Shot Semantic Segmentation.](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_MIANet_Aggregating_Unbiased_Instance_and_General_Information_for_Few-Shot_Semantic_CVPR_2023_paper.pdf)
- ###### [2023 ICCV] [Prototypical Kernel Learning and Open-set Foreground Perception for Generalized Few-shot Semantic Segmentation.](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Prototypical_Kernel_Learning_and_Open-set_Foreground_Perception_for_Generalized_Few-shot_ICCV_2023_paper.pdf)
- ###### [2022 CVPR] [Generalized Few-shot Semantic Segmentation.](https://openaccess.thecvf.com/content/CVPR2022/papers/Tian_Generalized_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf)

### Openable part detection
- ###### [2024 NIPS] [Detection Based Part-level Articulated Object Reconstruction from Single RGBD Image.](https://proceedings.neurips.cc/paper_files/paper/2023/file/3af8c40dcf1bc94fa570a5e42edf219d-Paper-Conference.pdf)
- ###### [2024 3DV] [OPDMulti: Openable Part Detection for Multiple Objects.](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10550888)
- ###### [2022 ECCV] [OPD: Single-view 3D Openable Part Detection.](https://link.springer.com/chapter/10.1007/978-3-031-19842-7_24)

### Weakly-supervised segmentation
#### Box-level
- ###### [2024 ECCV] [WPS-SAM: Towards Weakly-Supervised Part Segmentation withÂ Foundation Models.](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/06063.pdf)
- ###### [2021 CVPR] [Background-aware pooling and noise-aware loss for weakly-supervised semantic segmentation.](https://openaccess.thecvf.com/content/CVPR2021/papers/Oh_Background-Aware_Pooling_and_Noise-Aware_Loss_for_Weakly-Supervised_Semantic_Segmentation_CVPR_2021_paper.pdf)
- ###### [2019 NIPS] [Weakly supervised instance segmentation using the bounding box tightness prior.](https://proceedings.neurips.cc/paper/2019/file/e6e713296627dff6475085cc6a224464-Paper.pdf)
- ###### [2018 ECCV] [Weakly- and semi-supervised panoptic segmentation.](https://openaccess.thecvf.com/content_ECCV_2018/papers/Anurag_Arnab_Weakly-_and_Semi-Supervised_ECCV_2018_paper.pdf)
- ###### [2017 CVPR] [Simple does it: Weakly supervised instance and semantic segmentation.](https://openaccess.thecvf.com/content_cvpr_2017/papers/Khoreva_Simple_Does_It_CVPR_2017_paper.pdf)

#### Scribble-level 
- ###### [2022 CVPR] [Semi-Supervised Semantic Segmentation Using Unreliable Pseudo-Labels.](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Semi-Supervised_Semantic_Segmentation_Using_Unreliable_Pseudo-Labels_CVPR_2022_paper.pdf)
- ###### [2022 CVPR] [Adaptive early-learning correction for segmentation from noisy annotations.](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Adaptive_Early-Learning_Correction_for_Segmentation_From_Noisy_Annotations_CVPR_2022_paper.pdf)
- ###### [2021 ICLR]  [Pseudoseg: Designing pseudo labels for semantic segmentation.](https://openreview.net/pdf?id=-TwO99rbVRu)
- ###### [2021 CVPR] [Semi-supervised semantic segmentation with directional context-aware consistency.](https://openaccess.thecvf.com/content/CVPR2021/papers/Lai_Semi-Supervised_Semantic_Segmentation_With_Directional_Context-Aware_Consistency_CVPR_2021_paper.pdf)
- ###### [2016 CVPR] [Scribblesup: Scribble supervised convolutional networks for semantic segmentation.](https://openaccess.thecvf.com/content_cvpr_2016/papers/Lin_ScribbleSup_Scribble-Supervised_Convolutional_CVPR_2016_paper.pdf)

### Unsupervised vision feature extraction
- ###### [2024 TMLR] [DINOv2: Learning Robust Visual Features without Supervision.](https://openreview.net/pdf?id=a68SUt6zFt)
-  

